# 6. 故障排除与优化

在使用 EvoX 的过程中，您可能会遇到一些问题或需要对算法进行优化调整。本章汇总了常见问题及其解决方案，并提供了一些调试技巧和性能调优指南，帮助您顺利排除障碍并优化使用体验。

---

## 6.1 常见问题及解决方案

以下列出了一些新手常遇到的问题及应对方法。

**（1）安装或导入错误**：

- **问题描述**：安装后执行 `import evox` 时遇到错误。
- **解决方案**：
  - 检查<u>是否安装成功</u>：运行 `pip show evox` 查看版本信息。如果找不到 evox，可能是安装失败或环境不对，请确保在您运行Python的环境中，EvoX已正确安装（例如虚拟环境的问题）。
  - 如果报错提示<u>缺少依赖</u>，例如 `ModuleNotFoundError: No module named 'torch'`，则说明 PyTorch 未安装或未安装成功，请查阅第2章重新安装相关依赖（参考 [EvoX Installation Guide — EvoX  Documentation](https://evox.readthedocs.io/en/latest/guide/install/install.html#:~:text=EvoX%20is%20available%20at%20PyPI,and%20can%20be%20installed%20via)）。
  - 若您在使用GPU，请检查<u>CUDA是否匹配</u>（如PyTorch版本与CUDA驱动版本是否兼容）。

**（2）GPU不可用**：

- **问题描述**：预期在 GPU 上运行，但实际使用了 CPU。
- **解决方案**：可能的原因有：<u>PyTorch未安装GPU版、驱动问题或环境变量设置问题</u>。建议首先使用 `torch.cuda.is_available()` 来检查GPU是否可用。
  - 如果返回 `False`，请重新安装支持 GPU 的 PyTorch 版本，并确保 CUDA 驱动正常工作。
  - 如果返回 `True`，即GPU 可用但 EvoX 仍运行在 CPU 上，请确保相关张量已移至 GPU 设备（见第三章配置运行环境部分）。

**（3）内存/显存不足**：

- **问题描述**：运行过程中出现 `OutOfMemoryError`（无论是CPU内存还是GPU显存）。
- **解决方案**：
  - 减小种群规模、降低问题维度或减少每代评估次数。
  - 对于GPU显存不足，可以尝试使用半精度计算（`float16`）或者拆分批次评估。
  - 确保关闭了不必要的调试模式（如PyTorch中的deterministic模式会增大内存）。
  - 对于多目标算法，如果帕累托集过大，可以仅存储关键统计信息而非完整解集信息。
  - 如果问题持续，升级硬件资源是解决内存问题的根本方法。

**（4）算法收敛停滞**：

- **问题描述**：算法陷入局部最优，无法继续优化。
- **解决方案**：该问题不属于框架问题，而是算法本身的行为导致。解决办法包括：
  - <u>增加种群多样性</u>，例如增大种群或引入变异扩散。
  - <u>尝试不同的算法或调整算法参数</u>，如增加变异概率。
  - <u>检查问题定义</u>是否合理，如目标函数是否平滑、是否存在过多局部极值。
  - 可以<u>尝试多次运行</u>取最佳结果，因为演化算法有随机性，多运行几次可减少偶然影响。借助 EvoX 的并行能力，您可以快速启动多次运行（例如开多个进程并行执行PSO算法），最后比较结果择优。

**（5）结果不理想**：

- **问题描述**：优化结果未达到预期水平。
- **解决方案**：您需要分析是问题原因导致还是算法原因导致。
  - <u>确保问题定义正确</u>，比如最小化目标是否正确实现（返回fitness值大小是否和期望一致，有无符号错误）。
  - <u>考虑算法适配度</u>，有些问题对某些算法来说比较困难，尝试更换算法或调整参数。
  - <u>利用监控器输出</u>的收敛曲线诊断问题：
    - 如果曲线快速下降后平稳，可能是早熟收敛。
    - 如果曲线震荡不降，可能是参数设置不当导致随机性过大。
  - 针对具体问题<u>调整算法和参数</u>。没有万能的优化算法，实验和调试是演化计算的正常工作流程。

**（6）与JAX/其他后端冲突**：

- **问题描述**：安装了 JAX 版本的 EvoX，使用了 PyTorch 版本提供的功能。
- **解决方案**：EvoX 支持多种计算后端，包括 PyTorch 和 JAX，对于仅需使用 PyTorch 的用户，可以完全忽略 JAX 相关内容。如果您无意中安装了JAX版EvoX，并参考了最新文档（PyTorch版本）进行使用，可能会遇到让您提供`PRNGKey` 等情况，这时您可以改为安装PyTorch版EvoX 并使用Torch语法。按照第2章的安装方法，默认安装的 EvoX 即为 Torch 后端，无需额外配置，如果您对 JAX 感兴趣，可以参考官方文档（[EvoX Documentation / JAX version](https://evox.readthedocs.io/en/v0.9.1-dev/index.html)）了解更多信息。

**（7）版本兼容问题**：

- **问题描述**：API 调用方式与当前版本不兼容。
- **解决方案**：随着 EvoX 的更新，一些API调用可能改变。例如旧版本的算法定义中使用 `ask` 和 `tell` 方法，而新版本改为使用 `step` 函数。如果参考的示例代码与当前版本不符，请以官方文档为准调整调用方式。阅读错误信息通常能帮助您定位版本接口，例如 `AttributeError` 提示找不到 `State`，那么表示当前版本可能将 `State` 模块删去了。解决方案通常是升级/降级 EvoX 到合适的版本，或更改代码调用匹配当前的版本。对初学者而言，建议始终使用最新稳定版本并参考对应版本的文档/教程。

---

## 6.2 Debug 技巧

调试演化算法可能比调试普通程序更具挑战性，因为算法的结果依赖于群体交互和随机过程。以下技巧可以帮助您更好地观察和排查问题。

**（1）小规模试验**：在调试阶段，建议您简化问题规模以降低复杂性。例如：

- 把种群规模降为很小（比如5）。
- 减少迭代次数（如迭代20次）。

这样便于<u>逐步打印每代的种群数据</u>，观察算法行为是否符合预期。如果自定义算法的某步骤有问题，小规模下更容易暴露（比如某代出现异常值）。虽然小规模结果未必代表正式规模的性能，但适合检查正确性。

**（2）插入打印**：在进化循环中<u>插入打印语句</u>，以监控算法状态。比如每隔几代打印当前最优适应度或某些个体的目标函数值，或是打印算法内部的中间变量（如果可访问的话）。对于并行的张量计算，建议您可以将张量转换为 NumPy 再打印，或直接打印张量的形状（如 ```print(tensor.shape)```）以了解维度变化，避免打印较大张量带来的冗长输出。
通过这些输出，您可以验证算法是否按预期执行，例如种群是否收敛、变异算子是否生效等。调试完成后，记得移除冗余的打印语句以避免性能影响。

**（3）使用断点**：在 IDE（如 PyCharm）中对Python代码<u>设置断点</u>进行debug。在调试模式下，当程序执行到了所设置的断点处，您可以在变量窗口检查当前变量的值。例如使用 EvoX 执行某进化算法时，可以在算法类的 `step` 函数中设置断点，查看传入的种群和适应度是否合理。如果您使用EvoX开发自定义模块，设置断点是非常有效的调试手段，需要注意的是检查大张量需谨慎，以免内存占用过高。

**（4）验证子函数**：如果您在调试过程中怀疑某个自定义算子存在问题，例如定义了一个 `crossover()` 函数，可以<u>单独测试</u>其输出，比如设计几个张量验证输出是否符合预期，不必每次都运行完整算法才看效果。拆解复杂问题可以显著提高调试效率，有时能事半功倍。

**（5）Profiling**：profiling 不仅用于性能优化，还能帮助您捕捉异常行为。PyTorch提供了 `torch.autograd.profiler.profile`用于<u>运行时间分析</u>，也可以使用简单的计时方法如 `time.time()` 前后打点来分析程序流。如果某一步陷入死循环或耗时巨大，通过这些方式可以看出程序在哪个函数调用卡住。

**（6）日志记录**：对于长时间运行的优化，建议您将<u>关键日志写入文件</u>，这样即使程序异常中止，也有记录可分析。例如将每代的最优值、平均值写入 `.csv` 文件，然后可以事后绘制图表以定位异常阶段。若程序崩溃没有Python层面的报错（比如CUDA错误导致kernel崩溃），日志有助于确定问题发生的具体位置。

总的来说，调试演化算法需要耐心和巧妙的方法,由于算法的随机性，即使没有报错，结果也可能不尽如人意。因此，调试和结果分析往往交织在一起。通过上述方法，您可以先确保程序正确运行，再进一步分析算法性能。

---

## 6.3 性能调优指南

在前面的章节中，我们已经讨论了如何优化算法效果，并介绍了一些调试技巧。为了帮助您进一步提升算法的运行速度和结果质量，本节将总结几个关键要点，助您在使用 EvoX 时实现更高效的性能调优。

**（1）循序渐进优化**：不要一开始就用最大规模数据和种群跑。建议按照以下步骤进行：

- <u>验证功能正确性</u>：先用小规模数据和种群运行，确保算法逻辑正确。
- <u>逐步增加规模</u>：逐步增加问题规模和种群大小，观察运行时间的增长趋势。
- <u>观察数据，识别瓶颈</u>：如果运行时间的增长远超预期（例如种群从 100 增加到 1000，时间增长超过 10 倍），可能存在未矢量化或资源未充分利用的问题。

**（2）监控资源利用**：在优化过程中，建议您尝试监控硬件资源的利用率以及内存占用。

- <u>工具使用</u>：使用 `nvidia-smi` 可以实时查看GPU显存和计算占用，Linux下的 `htop` 可查看CPU线程使用。
- <u>硬件利用率</u>：理想情况下，GPU 利用率应保持在较高水平（>50%）且保持忙碌状态。如果 GPU 利用率低而 CPU 利用率高，可能是计算任务集中在 CPU 或 GPU 在等待数据传输。这时需要检查数据是否及时搬到GPU，或者是否存在GPU和CPU频繁切换。
- <u>多线程优化</u>：如果发现单线程瓶颈，可以考虑启用PyTorch的多线程（通常默认打开）。

**（3）调整并行度**：

PyTorch通常会根据环境调整线程数，具体来说:
- <u>CPU并行度</u>：您可以通过 `torch.set_num_threads(n)` 设置CPU并行线程数量。如果优化问题本身涉及多线程（例如评估中使用其他并行库），需避免线程竞争。可以尝试不同线程数配置观察耗时。
- <u>GPU并行度</u>：GPU 通常无需手动设置多线程，但如果您使用`DataLoader`之类在评估中加载数据，可以调节其`num_workers`参数以优化性能。

**（4）善用批处理**：

将<u>计算批处理化</u>可以显著提升效率。例如，将50个个体一起评估通常比逐个评估50次快得多。在自定义 `Problem` 时，您需要确保评估函数支持批处理，可以参考 EvoX 内置问题的实现，学习如何生成批量输入并并行计算。

**（5）减少Python干预**：

为了提升 EvoX 的运行效率，应尽量减少主循环中每次迭代的纯 Python 操作。理想情况下，`workflow.step()` 内部的繁重计算应在底层C/CUDA中完成，而Python仅负责轻量级调用。如果主循环中包含复杂的 Python 逻辑，可以尝试以下优化方法：

- 将复杂逻辑移到 `Problem` 或 `Algorithm` 内部，并用张量计算替代。
- 降低调用频率，例如每隔几代算一次复杂指标等，而非每代都计算。

**（6）算法层调优**：

换算法有时可以更快达到目标，比如对于连续优化问题，CMA-ES 可能比 PSO 需要更少代数收敛，如果某算法在目标问题上调试了很久都效果不佳，不妨尝试另一种。注意，演化计算中效率不仅指运行速度，还包括收敛代数，用更少代找到可接受的解也是效率高的体现。EvoX提供了丰富的内置算法，多进行尝试可以帮助您找到更适合问题的算法。

性能调优是一个反复试验和积累经验的过程。通过逐步优化硬件资源利用、并行度、批处理和算法选择，您可以将运行时间从最初的一小时缩短到几分钟甚至更短。在EvoX中，您拥有大量调优“旋钮”，耐心调整可以让您的优化任务既高效又有效。
