{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bitkira/Colab/blob/main/tutorial_notebooks/textgrad_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/EvoAgentX/EvoAgentX.git"
      ],
      "metadata": {
        "id": "14pPfxpLYWXd"
      },
      "id": "14pPfxpLYWXd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 selenium html2text fastmcp"
      ],
      "metadata": {
        "id": "CiIvTUtYYWo8"
      },
      "id": "CiIvTUtYYWo8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6ac6fe3a",
      "metadata": {
        "id": "6ac6fe3a"
      },
      "source": [
        "# TextGrad Optimizer Tutorial\n",
        "\n",
        "This tutorial will guide you through the process of setting up and running the TextGrad optimizer in EvoAgentX. We'll use the [MATH](https://www.modelscope.cn/datasets/opencompass/competition_math) dataset as an example to demonstrate how to optimize the prompts\n",
        "and system prompts in a workflow.\n",
        "\n",
        "## 1. TextGrad\n",
        "TextGrad uses textual feedback from LLM to improve text variables. In EvoAgentX, we use TextGrad to optimize\n",
        "agents' prompts and system prompts. For more information on TextGrad, see their [paper](https://arxiv.org/abs/2406.07496) and [GitHub](https://github.com/zou-group/textgrad).\n",
        "\n",
        "## 2. TextGrad Optimizer\n",
        "The TextGrad optimizer in EvoAgentX enables you to:\n",
        "\n",
        "- Automatically optimize multi-agent workflows (prompts and/or system prompts)\n",
        "- Evaluate optimization results on datasets\n",
        "\n",
        "## 3. Setting Up the Environment\n",
        "\n",
        "First, let's import the necessary modules for setting up the TextGrad optimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a935052c",
      "metadata": {
        "id": "a935052c"
      },
      "outputs": [],
      "source": [
        "from evoagentx.benchmark import MATH\n",
        "from evoagentx.optimizers import TextGradOptimizer\n",
        "from evoagentx.models import OpenAILLMConfig, OpenAILLM\n",
        "from evoagentx.workflow import SequentialWorkFlowGraph\n",
        "from evoagentx.core.callbacks import suppress_logger_info\n",
        "from evoagentx.prompts import StringTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a4304bb",
      "metadata": {
        "id": "6a4304bb"
      },
      "source": [
        "\n",
        "### Configure the LLM Model\n",
        "You'll need a valid API key to initialize the LLM. See [Quickstart](../quickstart.md) for more details on how to set up your API key.\n",
        "\n",
        "`TextGradOptimizer` allows the use of different LLMs for workflow execution and optimization. For example, we can use GPT 4o-mini for workflow execution and GPT 4o for optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df2d2d3",
      "metadata": {
        "id": "9df2d2d3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from evoagentx.models import OpenAILLMConfig, OpenAILLM\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "except ImportError:\n",
        "    OPENAI_API_KEY = None\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    load_dotenv()  # Loads environment variables from .env file\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "executor_config = OpenAILLMConfig(model=\"gpt-4o-mini\", openai_key=OPENAI_API_KEY)\n",
        "executor_llm = OpenAILLM(config=executor_config)\n",
        "\n",
        "optimizer_config = OpenAILLMConfig(model=\"gpt-4o\", openai_key=OPENAI_API_KEY)\n",
        "optimizer_llm = OpenAILLM(config=optimizer_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df1a91d3",
      "metadata": {
        "id": "df1a91d3"
      },
      "source": [
        "\n",
        "## 3. Setting Up the Components\n",
        "\n",
        "### Step 1: Initialize the Workflow\n",
        "`TextGradOptimizer` only supports `SequentialWorkFlowGraph` and a specific variant of `WorkFlowGraph`. The workflow graph must have exactly one agent per node and each agent must only have one action. See [Workflow Graph](../modules/workflow_graph.md) for more information on `SequentialWorkFlowGraph` and `WorkFlowGraph`. For this example, let us create the\n",
        "simplest workflow with only a single node.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "030e0076",
      "metadata": {
        "id": "030e0076"
      },
      "outputs": [],
      "source": [
        "math_graph_data = {\n",
        "    \"goal\": r\"Answer the math question. The answer should be in box format, e.g., \\boxed{123}\",\n",
        "    \"tasks\": [\n",
        "        {\n",
        "            \"name\": \"answer_generate\",\n",
        "            \"description\": \"Answer generation for Math.\",\n",
        "            \"inputs\": [\n",
        "                {\"name\": \"problem\", \"type\": \"str\", \"required\": True, \"description\": \"The problem to solve.\"}\n",
        "            ],\n",
        "            \"outputs\": [\n",
        "                {\"name\": \"answer\", \"type\": \"str\", \"required\": True, \"description\": \"The generated answer.\"}\n",
        "            ],\n",
        "            \"prompt_template\": StringTemplate(instruction=\"Answer the math question. The answer should be in box format, e.g., \\\\boxed{{123}}\"),\n",
        "            \"parse_mode\": \"str\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "workflow_graph = SequentialWorkFlowGraph.from_dict(math_graph_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63486f04",
      "metadata": {
        "id": "63486f04"
      },
      "source": [
        "\n",
        "`TextGradOptimizer` requires each agent be configured with a prompt template, rather than specifying the prompt using a string. This allows for a clear separation between the part of the prompt intended for optimization (i.e. instruction) and those that should remain unchanged (e.g. context, demonstrations). For more information on prompt templates, see [Prompt Template](../modules/prompt_template.md).\n",
        "\n",
        "\n",
        "### Step 2: Prepare the dataset\n",
        "\n",
        "For this tutorial, we will use the MATH dataset which consists of challenging competition mathematics problems,\n",
        "spanning various difficulty levels and subject areas. The dataset is split into 7.5K training problems and 5K test problems. For demonstration purpose, let's take a smaller subset of the dataset to speed up the validation and evaluation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a695969",
      "metadata": {
        "id": "2a695969"
      },
      "outputs": [],
      "source": [
        "class MathSplits(MATH):\n",
        "    def _load_data(self):\n",
        "        super()._load_data()\n",
        "        import numpy as np\n",
        "        np.random.seed(42)\n",
        "        permutation = np.random.permutation(len(self._test_data))\n",
        "        full_test_data = self._test_data\n",
        "        # randomly select 10 samples for train, 40 for dev and 100 for test\n",
        "        self._train_data = [full_test_data[idx] for idx in permutation[:10]]\n",
        "        self._dev_data = [full_test_data[idx] for idx in permutation[10:50]]\n",
        "        self._test_data = [full_test_data[idx] for idx in permutation[50:150]]\n",
        "\n",
        "math_splits = MathSplits()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d44c42",
      "metadata": {
        "id": "e8d44c42"
      },
      "source": [
        "\n",
        "During optimization, the `TextGradOptimizer` will evaluate the performance on the development set by default. Please make sure the dataset has a development set properly set up (i.e., `benchmark._dev_data` is not None). You can either:\n",
        "   - Use a dataset that already provides a development set\n",
        "   - Split your dataset to create a development set (like in the example above)\n",
        "   - Implement a custom dataset (inherits from `evoagentx.benchmark.Benchmark`) that properly sets up the development set.\n",
        "\n",
        "\n",
        "### Step 3: Set Up the Evaluator\n",
        "\n",
        "The evaluator is responsible for assessing the performance of the workflow during optimization. For more detailed information about how to set up and use the evaluator, please refer to the [Benchmark and Evaluation Tutorial](./benchmark_and_evaluation.md).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92aab1a",
      "metadata": {
        "id": "a92aab1a"
      },
      "outputs": [],
      "source": [
        "from evoagentx.evaluators import Evaluator\n",
        "from evoagentx.agents import AgentManager\n",
        "def collate_func(example: dict) -> dict:\n",
        "    return {\"problem\": example[\"problem\"]}\n",
        "\n",
        "agent_manager = AgentManager()\n",
        "llm_config = OpenAILLMConfig(model=\"gpt-4o-mini\", openai_key=OPENAI_API_KEY, stream=True, output_response=True)\n",
        "llm = OpenAILLM(llm_config)\n",
        "evaluator = Evaluator(\n",
        "    llm=llm,\n",
        "    agent_manager=agent_manager,\n",
        "    collate_func=collate_func,\n",
        "    num_workers=5,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50c9c3f",
      "metadata": {
        "id": "d50c9c3f"
      },
      "source": [
        "\n",
        "## 4. Configuring and Running the TextGrad Optimizer\n",
        "\n",
        "The TextGradOptimizer can be configured with various parameters to control the optimization process:\n",
        "\n",
        "- `graph`: The workflow graph to optimize\n",
        "- `optimize_mode`: The mode of optimization:\n",
        "    * \"all\": optimize both instruction prompts and system prompts\n",
        "    * \"instruction\": optimize only the instruction prompts\n",
        "    * \"system_prompt\": optimize only the system prompts\n",
        "- `executor_llm`: The LLM used to execute the workflow\n",
        "- `optimizer_llm`: The LLM used to optimize the workflow\n",
        "- `batch_size`: The batch size for optimization\n",
        "- `max_steps`: The maximum number of optimization steps\n",
        "- `evaluator`: The evaluator to perform evaluation during optimization.\n",
        "- `eval_interval`: The number of steps between evaluations\n",
        "- `eval_rounds`: The number of evaluation rounds\n",
        "- `eval_config`: The evaluation configuration during optimization (passed to `TextGradOptimizer.evaluate()`). For example, if we don't want to evaluate on the entire development set, we can set  `eval_config = {\"sample_k\": 100}` to only evaluate on 100 random samples from the development set.\n",
        "- `save_interval`: The number of steps between saving the workflow graph\n",
        "- `save_path`: The path to save the workflow graph\n",
        "- `rollback`: Whether to rollback to the best workflow graph during optimization\n",
        "- `constraints`: An optional list of constraints for optimization. For example, \"The system prompt must not exceed 100 words\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51389510",
      "metadata": {
        "id": "51389510"
      },
      "outputs": [],
      "source": [
        "textgrad_optimizer = TextGradOptimizer(\n",
        "    graph=workflow_graph,\n",
        "    optimize_mode=\"all\",\n",
        "    executor_llm=executor_llm,\n",
        "    optimizer_llm=optimizer_llm,\n",
        "    batch_size=3,\n",
        "    max_steps=20,\n",
        "    evaluator=evaluator,\n",
        "    eval_every_n_steps=1,\n",
        "    eval_rounds=1,\n",
        "    save_interval=None,\n",
        "    save_path=\"./\",\n",
        "    rollback=True,\n",
        "    constraints=[]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178756ed",
      "metadata": {
        "id": "178756ed"
      },
      "source": [
        "\n",
        "### Running the Optimization\n",
        "\n",
        "To start the optimization process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a5fcb3",
      "metadata": {
        "id": "50a5fcb3"
      },
      "outputs": [],
      "source": [
        "textgrad_optimizer.optimize(dataset=math_splits, seed=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2107e4",
      "metadata": {
        "id": "2f2107e4"
      },
      "source": [
        "The `seed` is used for shuffling the training data. The training data is automatically re-shuffled every epoch. If `seed` is\n",
        "provided, the effective seed for shuffling the training data is `seed + epoch`.\n",
        "\n",
        "The final graph at the end of the optimization is not necessarily the best graph. If you wish to restore the graph that performed best on the development set, simply call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b234aecf",
      "metadata": {
        "id": "b234aecf"
      },
      "outputs": [],
      "source": [
        "textgrad_optimizer.restore_best_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43666471",
      "metadata": {
        "id": "43666471"
      },
      "source": [
        "\n",
        "We can evaluate the workflow again to see the improvement after optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818d945f",
      "metadata": {
        "id": "818d945f"
      },
      "outputs": [],
      "source": [
        "with suppress_logger_info():\n",
        "    result = textgrad_optimizer.evaluate(dataset=math_splits, eval_mode=\"test\")\n",
        "print(f\"Evaluation result (after optimization):\\n{result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfe57755",
      "metadata": {
        "id": "bfe57755"
      },
      "source": [
        "\n",
        "`TextGradOptimizer` always saves the final workflow graph and the best workflow graph to `save_path`. It also saves graphs during optimization if `save_interval` is not `None`. You can also save the workflow graph manually by calling `textgrad_optimizer.save()`.\n",
        "\n",
        "\n",
        "Note that `TextGradOptimizer` does not change the workflow structure but saving the workflow graph also saves the prompts and system prompts which will be different after optimization.\n",
        "Below is an example of a saved workflow graph after optimization using `TextGradOptimizer`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8d56ac",
      "metadata": {
        "id": "5d8d56ac"
      },
      "outputs": [],
      "source": [
        "{\n",
        "    \"class_name\": \"SequentialWorkFlowGraph\",\n",
        "    \"goal\": \"Answer the math question. The answer should be in box format, e.g., \\\\boxed{123}\",\n",
        "    \"tasks\": [\n",
        "        {\n",
        "            \"name\": \"answer_generate\",\n",
        "            \"description\": \"Answer generation for Math.\",\n",
        "            \"inputs\": [\n",
        "                {\n",
        "                    \"name\": \"problem\",\n",
        "                    \"type\": \"str\",\n",
        "                    \"description\": \"The problem to solve.\",\n",
        "                    \"required\": true\n",
        "                }\n",
        "            ],\n",
        "            \"outputs\": [\n",
        "                {\n",
        "                    \"name\": \"answer\",\n",
        "                    \"type\": \"str\",\n",
        "                    \"description\": \"The generated answer.\",\n",
        "                    \"required\": true\n",
        "                }\n",
        "            ],\n",
        "            \"prompt\": null,\n",
        "            \"prompt_template\": {\n",
        "                \"class_name\": \"StringTemplate\",\n",
        "                \"instruction\": \"To solve the math problem, follow these steps:\\n\\n1. **Contextual Overview**: Begin with a brief overview of the problem-solving strategy, using logical reasoning and mathematical principles to derive the solution. Include any relevant geometric or algebraic insights.\\n\\n2. **Key Steps Identification**: Break down the problem-solving process into distinct parts:\\n   - Identify the relevant mathematical operations and properties, such as symmetry, roots of unity, or trigonometric identities.\\n   - Perform the necessary calculations, ensuring each step logically follows from the previous one.\\n   - Present the final answer.\\n\\n3. **Conciseness and Clarity**: Provide a clear and concise explanation of your solution, avoiding unnecessary repetition. Use consistent formatting and notation throughout.\\n\\n4. **Mathematical Justification**: Explain the reasoning behind each step to ensure the solution is well-justified. Include explanations of reference angles, geometric interpretations, and any special conditions or edge cases.\\n\\n5. **Verification Step**: Include a quick verification step to confirm the accuracy of your calculations. Consider recalculating key values if initial assumptions were incorrect.\\n\\n6. **Visual Aids**: Where applicable, include diagrams or sketches to visually represent the problem and solution, enhancing understanding.\\n\\n7. **Final Answer Presentation**: Present the final answer clearly and ensure it is boxed, reflecting the correct solution. Verify that it aligns with the problem's requirements and any known correct solutions.\"\n",
        "            },\n",
        "            \"system_prompt\": \"You are a math-focused assistant dedicated to providing clear, concise, and educational solutions to mathematical problems. Your goal is to deliver structured and pedagogically sound explanations, ensuring mathematical accuracy and logical reasoning. Begin with a brief overview of the problem-solving approach, followed by detailed calculations, and conclude with a verification step. Use precise mathematical notation and consider potential edge cases. Present the final answer clearly, using the specified format, and incorporate visual aids or analogies where appropriate to enhance understanding and engagement. \\n\\nExplicitly include geometric explanations when applicable, describing the geometric context and relationships. Emphasize the importance of visual aids, such as diagrams or sketches, to enhance understanding. Ensure consistency in formatting and mathematical notation. Provide a brief explanation of the reference angle concept and its significance. Include contextual explanations of trigonometric identities and their applications. Critically evaluate initial assumptions and verify geometric properties before proceeding. Highlight the use of symmetry and conjugate pairs in complex numbers. Encourage re-evaluation and verification of steps, ensuring logical flow and clarity. Focus on deriving the correct answer and consider problem-specific strategies or known techniques.\",\n",
        "            \"parse_mode\": \"str\",\n",
        "            \"parse_func\": null,\n",
        "            \"parse_title\": null\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce172ee1",
      "metadata": {
        "id": "ce172ee1"
      },
      "source": [
        "\n",
        "For a complete working example, please refer to [examples/textgrad/math_textgrad.py](https://github.com/EvoAgentX/EvoAgentX/blob/main/examples/optimization/textgrad/math_textgrad.py). Additional TextGrad optimization scripts for other datasets (e.g., [`hotpotqa_textgrad.py`](https://github.com/EvoAgentX/EvoAgentX/blob/main/examples/optimization/textgrad/hotpotqa_textgrad.py) and [`mbqq_textgrad.py`](https://github.com/EvoAgentX/EvoAgentX/blob/main/examples/optimization/textgrad/mbpp_textgrad.py)) are available in the [examples/optimization/textgrad](https://github.com/EvoAgentX/EvoAgentX/tree/main/examples/optimization/textgrad) directory."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}